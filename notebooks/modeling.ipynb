{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5892b033",
   "metadata": {},
   "source": [
    "# Modelagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81446a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import warnings\n",
    "\n",
    "# remoção segura para deixar o log mais limpo\n",
    "warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccde5257",
   "metadata": {},
   "source": [
    "## Pré-processamento dos dados para o modelo "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fdb854",
   "metadata": {},
   "source": [
    "Leitura do dataset de features e covertendo os tipos dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0d3e9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura do dataset\n",
    "dataset_features_v1 = pd.read_csv('../data/processed/dataset_features_v1.csv')\n",
    "\n",
    "# Conversão dos tipos numéricos e categóricos\n",
    "dataset_features_v1 = dataset_features_v1.astype({\n",
    "    'ID_CLIENTE': 'int64',\n",
    "    'VALOR_A_PAGAR': 'float64',\n",
    "    'TAXA': 'float64',\n",
    "    'RENDA_MES_ANTERIOR': 'float64',\n",
    "    'NO_FUNCIONARIOS': 'int64',\n",
    "    'FLAG_PF': 'int64',\n",
    "    'DIAS_ATRASO': 'int64',\n",
    "    'TARGET_INADIMPLENCIA': 'int64',\n",
    "    'DIAS_ADIANTAMENTO': 'int64',\n",
    "    'TEMPO_DE_CASA_MESES': 'int64',\n",
    "    'PRAZO_PAGAMENTO_DIAS': 'int64',\n",
    "    'MES_SAFRA': 'int32',\n",
    "    'INADIMPLENCIAS_ANTERIORES': 'int64',\n",
    "    'SEGMENTO_INDUSTRIAL': 'category',\n",
    "    'DOMINIO_EMAIL': 'category',\n",
    "    'PORTE': 'category',\n",
    "    'CEP_2_DIG': 'category',\n",
    "})\n",
    "\n",
    "# Conversão de datas\n",
    "dataset_features_v1['SAFRA_REF'] = pd.to_datetime(\n",
    "    dataset_features_v1['SAFRA_REF'], format='%Y-%m-%d', errors='coerce'\n",
    ")\n",
    "\n",
    "dataset_features_v1['DATA_EMISSAO_DOCUMENTO'] = pd.to_datetime(\n",
    "    dataset_features_v1['DATA_EMISSAO_DOCUMENTO'], format='%Y-%m-%d', errors='coerce'\n",
    ")\n",
    "\n",
    "dataset_features_v1['DATA_PAGAMENTO'] = pd.to_datetime(\n",
    "    dataset_features_v1['DATA_PAGAMENTO'], format='%Y-%m-%d', errors='coerce'\n",
    ")\n",
    "\n",
    "dataset_features_v1['DATA_VENCIMENTO'] = pd.to_datetime(\n",
    "    dataset_features_v1['DATA_VENCIMENTO'], format='%Y-%m-%d', errors='coerce'\n",
    ")\n",
    "\n",
    "dataset_features_v1['DATA_CADASTRO'] = pd.to_datetime(\n",
    "    dataset_features_v1['DATA_CADASTRO'], format='%Y-%m-%d', errors='coerce'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e679a2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "e8e6582c-b35b-4b5d-9ab7-21b95dd64dd9",
       "rows": [
        [
         "ID_CLIENTE",
         "int64"
        ],
        [
         "SAFRA_REF",
         "datetime64[ns]"
        ],
        [
         "DATA_EMISSAO_DOCUMENTO",
         "datetime64[ns]"
        ],
        [
         "DATA_PAGAMENTO",
         "datetime64[ns]"
        ],
        [
         "DATA_VENCIMENTO",
         "datetime64[ns]"
        ],
        [
         "VALOR_A_PAGAR",
         "float64"
        ],
        [
         "TAXA",
         "float64"
        ],
        [
         "RENDA_MES_ANTERIOR",
         "float64"
        ],
        [
         "NO_FUNCIONARIOS",
         "int64"
        ],
        [
         "DATA_CADASTRO",
         "datetime64[ns]"
        ],
        [
         "FLAG_PF",
         "int64"
        ],
        [
         "SEGMENTO_INDUSTRIAL",
         "category"
        ],
        [
         "DOMINIO_EMAIL",
         "category"
        ],
        [
         "PORTE",
         "category"
        ],
        [
         "CEP_2_DIG",
         "category"
        ],
        [
         "DIAS_ATRASO",
         "int64"
        ],
        [
         "TARGET_INADIMPLENCIA",
         "int64"
        ],
        [
         "DIAS_ADIANTAMENTO",
         "int64"
        ],
        [
         "TEMPO_DE_CASA_MESES",
         "int64"
        ],
        [
         "PRAZO_PAGAMENTO_DIAS",
         "int64"
        ],
        [
         "MES_SAFRA",
         "int32"
        ],
        [
         "INADIMPLENCIAS_ANTERIORES",
         "int64"
        ],
        [
         "ADIANTAMENTOS_ANTERIORES",
         "int64"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 23
       }
      },
      "text/plain": [
       "ID_CLIENTE                            int64\n",
       "SAFRA_REF                    datetime64[ns]\n",
       "DATA_EMISSAO_DOCUMENTO       datetime64[ns]\n",
       "DATA_PAGAMENTO               datetime64[ns]\n",
       "DATA_VENCIMENTO              datetime64[ns]\n",
       "VALOR_A_PAGAR                       float64\n",
       "TAXA                                float64\n",
       "RENDA_MES_ANTERIOR                  float64\n",
       "NO_FUNCIONARIOS                       int64\n",
       "DATA_CADASTRO                datetime64[ns]\n",
       "FLAG_PF                               int64\n",
       "SEGMENTO_INDUSTRIAL                category\n",
       "DOMINIO_EMAIL                      category\n",
       "PORTE                              category\n",
       "CEP_2_DIG                          category\n",
       "DIAS_ATRASO                           int64\n",
       "TARGET_INADIMPLENCIA                  int64\n",
       "DIAS_ADIANTAMENTO                     int64\n",
       "TEMPO_DE_CASA_MESES                   int64\n",
       "PRAZO_PAGAMENTO_DIAS                  int64\n",
       "MES_SAFRA                             int32\n",
       "INADIMPLENCIAS_ANTERIORES             int64\n",
       "ADIANTAMENTOS_ANTERIORES              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_features_v1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a4dec0",
   "metadata": {},
   "source": [
    "#### Remoção de colunas irrelevantes\n",
    "\n",
    "Comecei eliminando colunas que não agregam valor ao modelo.\n",
    "\n",
    "* **ID_CLIENTE** é apenas um identificador único, não possui utilidade preditiva.\n",
    "* As colunas de datas brutas (**DATA_EMISSAO_DOCUMENTO**, **DATA_PAGAMENTO**, **DATA_VENCIMENTO**, **DATA_CADASTRO** e **SAFRA_REF**) foram removidas porque já foram utilizadas para criar variáveis derivadas mais informativas.\n",
    "\n",
    "#### Prevenção de data leakage\n",
    "\n",
    "* As variáveis **DIAS_ATRASO** e **DIAS_ADIANTAMENTO** foram retiradas porque só estariam disponíveis após o vencimento, ou seja, depois da ocorrência ou não da inadimplência.\n",
    "* Manter essas colunas geraria vazamento de informação (data leakage), prejudicando a generalização do modelo e provocando overfitting.\n",
    "\n",
    "#### Codificação de variáveis categóricas\n",
    "\n",
    "* As variáveis **SEGMENTO_INDUSTRIAL**, **PORTE** e **DOMINIO_EMAIL**, por serem categóricas com baixa cardinalidade, foram tratadas com One-Hot Encoding.\n",
    "* Já a variável **CEP_2_DIG** apresenta alta cardinalidade, e por isso utilizei Frequency Encoding, uma técnica que substitui cada categoria pela frequência relativa com que aparece na base de dados. Isso evita a explosão de colunas sem perder a representatividade da variável.\n",
    "\n",
    "#### Separação dos dados\n",
    "\n",
    "* Após o pré-processamento, separei as variáveis explicativas (**X**) da variável alvo (**TARGET_INADIMPLENCIA**).\n",
    "* Em seguida, fiz a divisão entre treino e teste com **train_test_split**, utilizando **stratify=y** para garantir a mesma proporção de inadimplentes em ambas as amostras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69376d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar colunas irrelevantes\n",
    "cols_drop = [\n",
    "    'ID_CLIENTE', 'DATA_EMISSAO_DOCUMENTO', 'DATA_PAGAMENTO',\n",
    "    'DATA_VENCIMENTO', 'DATA_CADASTRO', 'SAFRA_REF',\n",
    "    'DIAS_ATRASO', 'DIAS_ADIANTAMENTO', # Colunas que só são conhecidas depois do treinamento. São removidas para evitar data leakage\n",
    "]\n",
    "\n",
    "df = dataset_features_v1.drop(columns=cols_drop)\n",
    "\n",
    "\n",
    "# Aplicando One-Hot Encoding em variáveis categóricas de baixa cardinalidade\n",
    "df = pd.get_dummies(df, columns=['SEGMENTO_INDUSTRIAL', 'PORTE', 'DOMINIO_EMAIL'], drop_first=True)\n",
    "\n",
    "# Aplicando Frequency Encoding para variável com alta cardinalidade \n",
    "freq_map = df['CEP_2_DIG'].value_counts(normalize=True)\n",
    "df['CEP_2_DIG'] = df['CEP_2_DIG'].map(freq_map)\n",
    "\n",
    "# Importante não adionar a variável target, resultaria em data leackage e consequentemente overfitting\n",
    "X = df.drop(columns='TARGET_INADIMPLENCIA')\n",
    "y = df['TARGET_INADIMPLENCIA']\n",
    "\n",
    "# Divisão treino/teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d24508",
   "metadata": {},
   "source": [
    "## Escolhendo o modelo preditor e seus parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f908fb9",
   "metadata": {},
   "source": [
    "Explicação do que eu estou fazendo aqui embaixo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40df0681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Treinando: XGBoost\n",
      "Fitting 5 folds for each of 184320 candidates, totalling 921600 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 134\u001b[0m\n\u001b[0;32m    119\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline(steps\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m    120\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m\"\u001b[39m, StandardScaler()),\n\u001b[0;32m    121\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmote\u001b[39m\u001b[38;5;124m\"\u001b[39m, SMOTE(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)),\n\u001b[0;32m    122\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclf\u001b[39m\u001b[38;5;124m\"\u001b[39m, modelo)\n\u001b[0;32m    123\u001b[0m ])\n\u001b[0;32m    125\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[0;32m    126\u001b[0m     pipeline,\n\u001b[0;32m    127\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mgrid_params,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    131\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    132\u001b[0m )\n\u001b[1;32m--> 134\u001b[0m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m    137\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\Matheus\\miniconda3\\envs\\py310\\lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Matheus\\miniconda3\\envs\\py310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1020\u001b[0m     )\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Matheus\\miniconda3\\envs\\py310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1571\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Matheus\\miniconda3\\envs\\py310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    967\u001b[0m         )\n\u001b[0;32m    968\u001b[0m     )\n\u001b[1;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Matheus\\miniconda3\\envs\\py310\\lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Matheus\\miniconda3\\envs\\py310\\lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Matheus\\miniconda3\\envs\\py310\\lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Matheus\\miniconda3\\envs\\py310\\lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Para o XGBoost.\n",
    "# scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "\n",
    "'''\n",
    "modelos_parametros = {\n",
    "    \"XGBoost\": (\n",
    "        XGBClassifier(\n",
    "            #use_label_encoder=False,\n",
    "            objective=\"binary:logistic\",\n",
    "            eval_metric=\"logloss\",\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        {\n",
    "            \"clf__n_estimators\": [100, 200, 300],\n",
    "            \"clf__max_depth\": [3, 5, 7, 10],\n",
    "            \"clf__learning_rate\": [0.01, 0.05, 0.1],\n",
    "            \"clf__subsample\": [0.6, 0.8, 1.0],\n",
    "            \"clf__colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "            \"clf__gamma\": [0, 1, 5],  # controle da complexidade\n",
    "            \"clf__min_child_weight\": [1, 5, 10],  # regularização de folhas\n",
    "        }\n",
    "    ),\n",
    "    \n",
    "    \"RandomForest\": (\n",
    "        RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "        {\n",
    "            \"clf__n_estimators\": [100, 200, 300],\n",
    "            \"clf__max_depth\": [None, 10, 20],\n",
    "            \"clf__min_samples_split\": [2, 5, 10],\n",
    "            \"clf__min_samples_leaf\": [1, 2, 4],\n",
    "            \"clf__max_features\": ['sqrt', 'log2'],  # diversificação\n",
    "            \"clf__bootstrap\": [True, False]\n",
    "        }\n",
    "    ),\n",
    "\n",
    "    \"LogisticRegression\": (\n",
    "        LogisticRegression(max_iter=1000, solver='lbfgs', random_state=42),\n",
    "        {\n",
    "            \"clf__C\": [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "        }\n",
    "    ),\n",
    "\n",
    "    \"LightGBM\": (\n",
    "        LGBMClassifier(random_state=42),\n",
    "        {\n",
    "            \"clf__n_estimators\": [100, 200, 300],\n",
    "            \"clf__num_leaves\": [31, 50, 100],\n",
    "            \"clf__learning_rate\": [0.01, 0.05, 0.1],\n",
    "            \"clf__min_child_samples\": [10, 20, 50],\n",
    "            \"clf__subsample\": [0.6, 0.8, 1.0],\n",
    "            \"clf__colsample_bytree\": [0.6, 0.8, 1.0]\n",
    "        }\n",
    "    )\n",
    "}\n",
    "'''\n",
    "\n",
    "\n",
    "modelos_parametros = {\n",
    "    \"XGBoost\": (\n",
    "        XGBClassifier(\n",
    "            objective=\"binary:logistic\",\n",
    "            eval_metric=\"logloss\",\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            tree_method='gpu_hist',\n",
    "            predictor='gpu_predictor',\n",
    "            #use_label_encoder=False\n",
    "        ),\n",
    "        {\n",
    "            \"clf__n_estimators\": [100, 200, 300, 400],\n",
    "            \"clf__max_depth\": [3, 5, 7, 10, 12],\n",
    "            \"clf__learning_rate\": [0.005, 0.01, 0.05, 0.1],\n",
    "            \"clf__subsample\": [0.5, 0.6, 0.8, 1.0],\n",
    "            \"clf__colsample_bytree\": [0.5, 0.6, 0.8, 1.0],\n",
    "            \"clf__gamma\": [0, 1, 3, 5],  # controle da complexidade\n",
    "            \"clf__min_child_weight\": [1, 3, 5, 10],\n",
    "            \"clf__reg_alpha\": [0, 0.1, 0.5],  # L1 regularização\n",
    "            \"clf__reg_lambda\": [1, 1.5, 2.0],  # L2 regularização\n",
    "        }\n",
    "    ),\n",
    "\n",
    "    \"RandomForest\": (\n",
    "        RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "        {\n",
    "            \"clf__n_estimators\": [100, 200, 300, 500],\n",
    "            \"clf__max_depth\": [None, 10, 20, 30],\n",
    "            \"clf__min_samples_split\": [2, 5, 10],\n",
    "            \"clf__min_samples_leaf\": [1, 2, 4],\n",
    "            \"clf__max_features\": ['sqrt', 'log2', None],\n",
    "            \"clf__bootstrap\": [True, False],\n",
    "            \"clf__criterion\": ['gini', 'entropy']\n",
    "        }\n",
    "    ),\n",
    "\n",
    "    \"LogisticRegression\": (\n",
    "        LogisticRegression(max_iter=1000, solver='lbfgs', random_state=42),\n",
    "        {\n",
    "            \"clf__C\": [0.1, 1.0, 10.0]\n",
    "        }\n",
    "    ),\n",
    "    \"LightGBM\": (\n",
    "        LGBMClassifier(random_state=42, verbose=-1),\n",
    "        {\n",
    "            \"clf__n_estimators\": [100, 200],\n",
    "            \"clf__num_leaves\": [31, 50],\n",
    "            \"clf__learning_rate\": [0.01, 0.1]\n",
    "        }\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "# Validação cruzada e execução \n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "resultados = {}\n",
    "\n",
    "for nome, (modelo, grid_params) in modelos_parametros.items():\n",
    "    print(f\"\\nTreinando: {nome}\")\n",
    "    pipeline = Pipeline(steps=[\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"smote\", SMOTE(random_state=42)),\n",
    "        (\"clf\", modelo)\n",
    "    ])\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grid=grid_params,\n",
    "        cv=cv,\n",
    "        scoring=\"roc_auc\",\n",
    "        verbose=3,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    resultados[nome] = {\n",
    "        \"Melhores parâmetros\": grid.best_params_,\n",
    "        \"ROC AUC (validação)\": grid.best_score_,\n",
    "        \"ROC AUC (teste)\": roc_auc_score(y_test, y_proba),\n",
    "        \"Classification Report\": classification_report(y_test, y_pred, output_dict=True),\n",
    "        \"Confusion Matrix\": confusion_matrix(y_test, y_pred).tolist()\n",
    "    }\n",
    "\n",
    "    print(resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278f5609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== XGBoost ===\n",
      "Melhores parâmetros: {'clf__colsample_bytree': 0.6, 'clf__gamma': 0, 'clf__learning_rate': 0.1, 'clf__max_depth': 10, 'clf__min_child_weight': 1, 'clf__n_estimators': 300, 'clf__subsample': 0.6}\n",
      "ROC AUC (validação): 0.9611\n",
      "ROC AUC (teste): 0.9591\n",
      "Classification Report:\n",
      "              precision    recall  f1-score      support\n",
      "0              0.974856  0.980987  0.977912  13675.00000\n",
      "1              0.739479  0.680812  0.708934   1084.00000\n",
      "accuracy       0.958940  0.958940  0.958940      0.95894\n",
      "macro avg      0.857168  0.830900  0.843423  14759.00000\n",
      "weighted avg   0.957569  0.958940  0.958157  14759.00000\n",
      "Confusion Matrix:\n",
      "[[13415   260]\n",
      " [  346   738]]\n",
      "\n",
      "=== RandomForest ===\n",
      "Melhores parâmetros: {'clf__bootstrap': False, 'clf__max_depth': 20, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 5, 'clf__n_estimators': 300}\n",
      "ROC AUC (validação): 0.9618\n",
      "ROC AUC (teste): 0.9618\n",
      "Classification Report:\n",
      "              precision    recall  f1-score       support\n",
      "0              0.980769  0.973382  0.977062  13675.000000\n",
      "1              0.693345  0.759225  0.724791   1084.000000\n",
      "accuracy       0.957653  0.957653  0.957653      0.957653\n",
      "macro avg      0.837057  0.866304  0.850926  14759.000000\n",
      "weighted avg   0.959659  0.957653  0.958533  14759.000000\n",
      "Confusion Matrix:\n",
      "[[13311   364]\n",
      " [  261   823]]\n",
      "\n",
      "=== LogisticRegression ===\n",
      "Melhores parâmetros: {'clf__C': 1.0}\n",
      "ROC AUC (validação): 0.8666\n",
      "ROC AUC (teste): 0.8682\n",
      "Classification Report:\n",
      "              precision    recall  f1-score      support\n",
      "0              0.977520  0.839488  0.903261  13675.00000\n",
      "1              0.271973  0.756458  0.400098   1084.00000\n",
      "accuracy       0.833390  0.833390  0.833390      0.83339\n",
      "macro avg      0.624747  0.797973  0.651679  14759.00000\n",
      "weighted avg   0.925700  0.833390  0.866306  14759.00000\n",
      "Confusion Matrix:\n",
      "[[11480  2195]\n",
      " [  264   820]]\n",
      "\n",
      "=== LightGBM ===\n",
      "Melhores parâmetros: {'clf__colsample_bytree': 0.6, 'clf__learning_rate': 0.1, 'clf__min_child_samples': 50, 'clf__n_estimators': 300, 'clf__num_leaves': 100, 'clf__subsample': 0.6}\n",
      "ROC AUC (validação): 0.9598\n",
      "ROC AUC (teste): 0.9586\n",
      "Classification Report:\n",
      "              precision    recall  f1-score      support\n",
      "0              0.975080  0.981426  0.978243  13675.00000\n",
      "1              0.744724  0.683579  0.712843   1084.00000\n",
      "accuracy       0.959550  0.959550  0.959550      0.95955\n",
      "macro avg      0.859902  0.832503  0.845543  14759.00000\n",
      "weighted avg   0.958161  0.959550  0.958750  14759.00000\n",
      "Confusion Matrix:\n",
      "[[13421   254]\n",
      " [  343   741]]\n"
     ]
    }
   ],
   "source": [
    "# Resultados Finais \n",
    "for nome, res in resultados.items():\n",
    "    print(f\"\\n=== {nome} ===\")\n",
    "    print(\"Melhores parâmetros:\", res[\"Melhores parâmetros\"])\n",
    "    print(\"ROC AUC (validação):\", round(res[\"ROC AUC (validação)\"], 4))\n",
    "    print(\"ROC AUC (teste):\", round(res[\"ROC AUC (teste)\"], 4))\n",
    "    print(\"Classification Report:\")\n",
    "    print(pd.DataFrame(res[\"Classification Report\"]).T)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(np.array(res[\"Confusion Matrix\"]))\n",
    "    #plotando a matriz de confusão \n",
    "    #cm = np.array(res[\"Confusion Matrix\"])\n",
    "    #disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "    #disp.plot(cmap=\"plasma\", values_format=\"d\")\n",
    "    #plt.title(f\"Matriz de Confusão - {nome}\")\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d81565d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Matheus\\miniconda3\\envs\\py310\\lib\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Treinamento concluído com GPU.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Gerar um dataset de exemplo\n",
    "X, y = make_classification(n_samples=10000, n_features=20, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Criar o modelo com uso explícito de GPU\n",
    "model = xgb.XGBClassifier(\n",
    "    tree_method='gpu_hist',         # Ativa o uso da GPU\n",
    "    predictor='gpu_predictor',      # Usa GPU também na predição\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "# Treinamento\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predição\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Confirmação\n",
    "print(\"✅ Treinamento concluído com GPU.\")\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500c7df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva\n",
    "with open(\"../data/processed/resultados_grid_search_cv_v5.pkl\", \"wb\") as f:\n",
    "    pickle.dump(resultados, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f3c3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Divide treino/teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Aplica SMOTE apenas no treino\n",
    "sm = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# Treina o modelo final\n",
    "xgb = XGBClassifier(**best_params)\n",
    "xgb.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Avalia no conjunto de teste real\n",
    "y_pred = xgb.predict(X_test)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
